---
layout: post
title: 自然语言处理（二）-word2vec
category: 自然语言处理
date: 2015-4-3
math: true
---

<!-- more -->
公司项目需求，需要对新闻信息进行文本挖掘。使用到了word2vec

word2vec 是 Google 在 2013 年年中开源的一款将词表征为实数值向量的高效工具，采用的模型有 CBOW（ Continuous Bag-Of-Words，即连续的词袋模型） 和Skip-Gram 两种。 word2vec 代码链接为： https://code.google.com/p/word2vec/，
遵循 Apache License 2.0 开源协议，是一种对商业应用友好的许可，当然需要充分尊重原作者的著作权。

word2vec 一般被外界认为是一个 Deep Learning（深度学习）的模型，究其原因，可能和 word2vec 的作者 Tomas Mikolov 的 Deep Learning 背景以及 word2vec是一种神经网络模型相关，但我们谨慎认为该模型层次较浅，严格来说还不能算
是深层模型。当然如果 word2vec 上层再套一层与具体应用相关的输出层，比如Softmax，此时更像是一个深层模型。

word2vec 通过训练，可以把对文本内容的处理简化为 K 维向量空间中的向量运算，而向量空间上的相似度可以用来表示文本语义上的相似度。因此， word2vec输出的词向量可以被用来做很多 NLP 相关的工作，比如聚类、找同义词、词性分
析等等。 而 word2vec 被人广为传颂的地方是其向量的加法组合运算（ AdditiveCompositionality ） ， 官 网 上 的 例 子 是 ： vector('Paris') - vector('France') +vector('Italy') ≈vector('Rome')， vector('king') - vector('man') + vector('woman') ≈vector('queen')。但我们认为这个多少有点被过度炒作了， 很多其他降维或主题
模型在一定程度也能达到类似效果，而且 word2vec 也只是少量的例子完美符合这种加减法操作，并不是所有的 case 都满足。

从github上checkOut下来了word2vec的java版本，通过训练一些搜狗的新闻语料后发现并不是很准确。总结出来的原因可能有两个：训练集不够大，中文分词不够准。
于是，将中文分词换为IK分词，同时用更大的搜狗新闻库训练。
下面是部分代码：
第一步，分词，将分词后的结果保存到一个文本文件中，每个词之间用空格分开：

{% highlight java %}
	private static final File sportCorpusFile = new File("f:\\Word2Vec\\result2.txt");
	private static final String filesPath = "F:\\SogouC.reduced\\Reduced\\files";

	@Test
	public void test1() throws IOException {
		File[] files = new File(filesPath).listFiles();
		FileOutputStream fos = new FileOutputStream(sportCorpusFile);

		Analyzer analyzer = new IKAnalyzer(true);
		for (File file : files) {
			System.out.println("FileName:" + file.getName());
			String str = analysis(file, analyzer);
			appendStrToOS(fos, str);
		}
		fos.flush();
		fos.close();
	}


		private String analysis(File file, Analyzer analyzer) {
    		StringBuffer accum = new StringBuffer();
    		TokenStream ts = null;
    		try {
    			String str = FileUtils.readFileToString(file, "GBK");
    			ts = analyzer.tokenStream("myfield", new StringReader(str));
    			CharTermAttribute term = ts.addAttribute(CharTermAttribute.class);
    			// 重置TokenStream（重置StringReader）
    			ts.reset();
    			while (ts.incrementToken()) {
    				accum.append(term.toString() + " ");
    			}
    			ts.end();
    		} catch (IOException e) {
    			e.printStackTrace();
    		} finally {
    			// 释放TokenStream的所有资源
    			if (ts != null) {
    				try {
    					ts.close();
    				} catch (IOException e) {
    					e.printStackTrace();
    				}
    			}
    		}
    		return String.valueOf(accum);
    	}

    	private void appendStrToOS(FileOutputStream fos, String str) {
    		try {
    			fos.write(str.getBytes());
    			fos.write("\n".getBytes());
    		} catch (IOException e) {
    			e.printStackTrace();
    		}
    	}
{% endhighlight %}

第二部，使用分词后的结果进行训练：

{% highlight java %}
	@Test
	public void test2() throws IOException {
		Learn lean = new Learn();
		lean.lean(sportCorpusFile);

		lean.saveModel(new File("f:\\Word2Vec\\model\\vector2.mod"));
		Word2VEC w2v = new Word2VEC();
		// w2v.loadGoogleModel("f:\\Word2Vec\\model\\vector.mod");
		w2v.loadJavaModel("f:\\Word2Vec\\model\\vector2.mod");
		System.out.println(w2v.distance("节日"));
	}
//测试节日的结果：[传统节日	0.61526424, 每逢	0.6077036, 节庆	0.5821239, 礼品	0.546462, 清明节	0.5427991, 泼水节	0.53755164, 喜庆	0.5293092, 赕	0.5277321, 丰盛	0.52379405, 隆重	0.52296424, 年节	0.5227545, 傣历	0.5221737, 尝新	0.5168969, 招待	0.5165517, 聚餐	0.5150969, 杀猪	0.5092655, 庆贺	0.5088396, 大过年	0.50879896, 热情好客	0.505684, guadalupe	0.5044676, 端午节	0.50259775, 家家	0.50236756, 农历	0.49830335, 过年	0.49788663, 火把节	0.4929935, 白族	0.49232218, 藏族	0.49008083, 丰收	0.48984745, 换工	0.48913446, 欢度	0.48899835, 习俗	0.48820457, 中秋节	0.4863722, 品尝	0.48433527, 藏历	0.48227873, 秋收	0.4814837, 亮节	0.480488, 古尔邦节	0.4782689, 寿糕	0.4776688, 仡佬族	0.47740144]

{% endhighlight %}


获取相似性的结果：

{% highlight java %}
	@Test
	public void test3() throws IOException{
		Word2VEC w2v = new Word2VEC();
		// w2v.loadGoogleModel("f:\\Word2Vec\\model\\vector.mod");
		w2v.loadJavaModel("f:\\Word2Vec\\model\\vector2.mod");

		//TreeSet<WordEntry> set= w2v.analogy("男人", "女人", "男孩");
		//结果：
				/**
        		 * 女孩:0.7179845
        熟得:0.59429854
        一个男孩:0.5882551
        女孩儿:0.56753725
        现像:0.56509686
        读写能力:0.564012
        跋扈:0.54586744
        守身如玉:0.5338605
        长舌妇:0.53169584
        扮像:0.5314307
        13岁:0.5305304
        哥们:0.5290446
        假小子:0.5290315
        啰嗦:0.5289817
        小时候:0.5251378
        弄过:0.5232353
        娃娃:0.5219303
        爱钱:0.51973504
        Comedian:0.51876205
        比她:0.5182113
        秀气:0.517856
        乖巧:0.51764315
        挎包:0.51435286
        称兄道弟:0.5140311
        儿时:0.5130685
        同龄:0.5129037
        打扮:0.5098146
        小孩子:0.5081016
        男性化:0.50807184
        啥子:0.5074133
        长笛:0.50463736
        长得:0.5036712
        赶去:0.5016238
        闲聊:0.50060266
        Standing:0.49991018
        小小年纪:0.49917623
        长大:0.4985421
        年长:0.49734166
        花花公子:0.49708867
        妒忌:0.495667
        		 */

		TreeSet<WordEntry> set= w2v.analogy("湖北", "武汉", "广东");
		//结果：
			/**
        		 * 广州:0.72742176
        南京:0.6799712
        上海:0.5741333
        法语系:0.5378342
        141人:0.51889473
        杭州:0.5064774
        深圳:0.5034209
        45.42:0.49169466
        北京:0.4912573
        昆明:0.4891703
        成都:0.48734218
        世界华人:0.48220667
        重庆:0.47922915
        苏州:0.47591838
        天津:0.4580782
        maurits&nbsp:0.45510638
        东莞:0.45389232
        山东大学:0.45310396
        太原:0.4518713
        经:0.4493839
        长沙:0.4478899
        中央:0.44147992
        桂林:0.43683618
        无锡:0.4364279
        报刊社:0.43565896
        大连:0.4342764
        香港:0.43343893
        国际饭店:0.43213633
        南昌:0.43095273
        韶山:0.4305477
        820元:0.43050134
        心怡:0.42893586
        潮安:0.42834783
        海洋大学:0.42730996
        开平:0.42709476
        华南理工:0.4242156
        某:0.4233318
        廿周年:0.42128372
        徐州:0.41949612
        扬州:0.4193639
        		 */

		for(WordEntry word:set){
			System.out.println(word.name+":"+word.score);
		}

	}

{% endhighlight %}





