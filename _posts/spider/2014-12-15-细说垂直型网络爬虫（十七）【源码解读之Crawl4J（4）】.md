---
layout: post
title: 细说垂直型网络爬虫（十七）【源码解读之Crawl4J（4）】
category: 细说垂直型网络爬虫
date: 2014-12-15

---

##细说垂直型网络爬虫（十七）【源码解读之Crawl4J（4）】

标签： 网络爬虫 开源爬虫源码解读 Crawl4J

###1.Crawl4J简介
Crawl4J是一个开源的Java爬虫程序，总共才三十多个类，比较简单，非常适合爬虫入门的学习。
（官方地址：https://code.google.com/p/crawler4j/）

<!-- more -->

###2.edu.uci.ics.crawler4j.frontier包
Counters：计数器
DocIDServer：URL的ID生成器
Frontier：URL调度器
InProcessPagesDB：尚未处理的URL队列
WorkQueues：URL队列
WebURLTupleBinding：自定义的绑定器（转换器）

Counters计数器主要记录已经抓取过了的URL数量和即将抓取的URL数量
DocIDServer可以根据URL获取到对应的ID，也可以根据URL生成新的ID
WebURLTupleBinding主要是将WebURL对象转化为berkeley db的DatabaseEntry以及将DatabaseEntry转化为WebURL
WorkQueues是URL队列，可以获取指定数量的URL，可以删除指定数量的URL
InProcessPagesDB继承自WorkQueues，是即将被抓取的URL。
Frontier是这个包中的核心类
(未完待续)





